{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Real Multilabel Training (MobileNetV2 + MLflow)\n",
        "\n",
        "This notebook trains a real multilabel image classifier for three classes:\n",
        "\n",
        "- lacteos (dairy products)\n",
        "\n",
        "- arroz (rice)\n",
        "\n",
        "- frutas/verduras (fruits and vegetables)\n",
        "\n",
        "The model predicts independent probabilities for each class (sigmoid outputs), allowing a single image to contain one, multiple, or none of the categories.\n",
        "\n",
        "✅ Key Technologies and Approach\n",
        "\n",
        "This training pipeline is built using modern TensorFlow practices:\n",
        "\n",
        "  - tf.data to build efficient input pipelines (loading, resizing, batching, prefetching)\n",
        "\n",
        "  - MobileNetV2 (ImageNet pretrained) as the feature extraction backbone (transfer learning)\n",
        "\n",
        "  - MLflow to log parameters, metrics, and artifacts (model checkpoints)\n",
        "\n",
        "A two-stage training strategy:\n",
        "\n",
        "      Stage 1 — Head training (head): train only the classification head while the backbone is frozen\n",
        "\n",
        "      Stage 2 — Fine-tuning (finetune): unfreeze the last layers of MobileNetV2 and continue training with a smaller learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f624ed5",
      "metadata": {},
      "source": [
        "\n",
        "# 1) IMPORTS + CONFIG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Root encontrado: c:\\Users\\HP OMEN\\Documents\\GitHub\\Food-Multi-Label-Classification-Pipeline-with-TensorFlow-Dataset-Builder\n",
            "✅ Working dir ahora: c:\\Users\\HP OMEN\\Documents\\GitHub\\Food-Multi-Label-Classification-Pipeline-with-TensorFlow-Dataset-Builder\n",
            "✅ Existe labels.csv?: True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "\n",
        "import os\n",
        "\n",
        "def find_project_root(start=\".\"):\n",
        "    here = os.path.abspath(start)\n",
        "    while True:\n",
        "        if os.path.isdir(os.path.join(here, \"dataset\")):\n",
        "            return here\n",
        "        parent = os.path.dirname(here)\n",
        "        if parent == here:\n",
        "            raise RuntimeError(\"No encontré la carpeta 'dataset' hacia arriba. Abre el proyecto correcto en VS Code.\")\n",
        "        here = parent\n",
        "\n",
        "PROJECT_ROOT = find_project_root(\".\")\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "\n",
        "\n",
        "print(\"✅ Root encontrado:\", PROJECT_ROOT)\n",
        "print(\"✅ Working dir ahora:\", os.getcwd())\n",
        "print(\"✅ Existe labels.csv?:\", os.path.exists(\"dataset/labels.csv\"))\n",
        "\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH = 32\n",
        "SEED = 42\n",
        "\n",
        "LABELS_CSV = \"dataset/labels.csv\"\n",
        "IMAGES_DIR = \"dataset/images\"\n",
        "OUT_DIR = \"outputs\"\n",
        "MODEL_PATH = os.path.join(OUT_DIR, \"model.keras\")\n",
        "\n",
        "# ✅ multilabel real (3 clases)\n",
        "CLASSES = [\"lacteos\", \"arroz\", \"frutas/verduras\"]\n",
        "\n",
        "# ✅ castigo para falsos positivos en \"NINGUNO\"\n",
        "NEG_WEIGHT = 4.0\n",
        "POS_WEIGHT = 1.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e32969",
      "metadata": {},
      "source": [
        "# 2) DATASET PIPELINE (tf.data input pipeline for multilabel training)\n",
        "\n",
        " This block builds an efficient TensorFlow input pipeline using tf.data.\n",
        " It converts a Pandas DataFrame into a dataset that yields:\n",
        "  (image_tensor, multilabel_vector, sample_weight)\n",
        "\n",
        " Why sample_weight?\n",
        " - Images labeled as \"NONE\" (0,0,0) are negative samples.\n",
        " - We want to penalize false positives more strongly on those samples.\n",
        " - Therefore, \"NONE\" samples get a higher weight (NEG_WEIGHT)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "28d079d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def make_ds(df, training: bool):\n",
        "    paths = df[\"path\"].values.astype(str)\n",
        "    y = df[CLASSES].values.astype(np.float32)\n",
        "\n",
        "     #Compute sample weights (extra penalty for NONE samples)\n",
        "    is_none = (y.sum(axis=1) == 0).astype(np.float32)\n",
        "    sw = np.where(is_none == 1.0, NEG_WEIGHT, POS_WEIGHT).astype(np.float32)\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, y, sw))\n",
        "\n",
        "    def _load(p, label, w):\n",
        "        img = tf.io.read_file(p)\n",
        "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "        img = tf.image.resize(img, IMG_SIZE)\n",
        "        img = tf.cast(img, tf.float32) / 255.0\n",
        "        return img, label, w\n",
        "    \n",
        "# Apply preprocessing, shuffling, batching, and prefetching\n",
        "    ds = ds.map(_load, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if training:\n",
        "        ds = ds.shuffle(2000, seed=SEED)\n",
        "    ds = ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f02bbc9",
      "metadata": {},
      "source": [
        "# 3) MODEL BUILD + COMPILE (MobileNetV2 transfer learning)\n",
        "\n",
        " This section defines:\n",
        "   - how the model is constructed (backbone + classification head)\n",
        "   - how it is compiled (optimizer, loss, metrics)\n",
        "   - how to unfreeze the last layers for fine-tuning\n",
        "\n",
        " Key idea:\n",
        " - We use MobileNetV2 pretrained on ImageNet as a feature extractor.\n",
        " - For multilabel classification, we use:\n",
        "     Dense(num_classes, activation=\"sigmoid\")\n",
        "    because each label is predicted independently (not mutually exclusive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "14f4b111",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def build_model():\n",
        "    base = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "    )\n",
        "    base.trainable = False\n",
        "\n",
        "    x_in = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = base(x_in, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    out = tf.keras.layers.Dense(len(CLASSES), activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(x_in, out)\n",
        "    return model\n",
        "\n",
        "\n",
        "def compile_model(model, lr: float):\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(lr),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\n",
        "            tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\"),\n",
        "            tf.keras.metrics.AUC(name=\"auc\"),\n",
        "        ],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# unfreeze_last_layers()\n",
        "# Used during Stage 2 (fine-tuning).\n",
        "\n",
        "def unfreeze_last_layers(model, n_layers=30):\n",
        "    \"\"\"\n",
        "    Descongela las últimas n_layers del backbone MobileNetV2.\n",
        "    \"\"\"\n",
        "    backbone = None\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.Model):\n",
        "            backbone = layer\n",
        "            break\n",
        "\n",
        "    if backbone is None:\n",
        "        print(\"⚠️ No encontré el backbone como submodelo.\")\n",
        "        return model\n",
        "\n",
        "    backbone.trainable = True\n",
        "    for layer in backbone.layers[:-n_layers]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7240069b",
      "metadata": {},
      "source": [
        "\n",
        "# 4) MLflow Callback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "99365099",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class MLflowMetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        for k, v in logs.items():\n",
        "            try:\n",
        "                mlflow.log_metric(k, float(v), step=epoch)\n",
        "            except Exception:\n",
        "                pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fc4f3b6",
      "metadata": {},
      "source": [
        "# 4) TRAINING CONFIGURATION (Notebook-friendly hyperparameters)\n",
        "\n",
        " In the notebook version we do NOT use argparse.\n",
        " Instead, we configure the training stage and hyperparameters here.\n",
        "\n",
        " Two-stage training strategy:\n",
        "   1) \"head\"     -> train only the classification head (backbone frozen)\n",
        "   2) \"finetune\" -> unfreeze the last layers of the backbone and continue training\n",
        "\n",
        " Recommended workflow:\n",
        "   - Run STAGE=\"head\" first\n",
        "   - Then run STAGE=\"finetune\" to improve final performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9002d17d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training stage selection\n",
        "\n",
        "STAGE = \"head\"      # Run \"head\" first, then \"finetune\"    \n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "# Learning rate\n",
        "LR = None\n",
        "\n",
        "# Fine-tuning configuration (only used when STAGE=\"finetune\")\n",
        "UNFREEZE_LAYERS = 30\n",
        "\n",
        "# MLflow experiment tracking\n",
        "MLFLOW_EXPERIMENT = \"multilabel_real_leche_arroz_fruta\"\n",
        "RUN_NAME = f\"{STAGE}_epochs{EPOCHS}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae94b07f",
      "metadata": {},
      "source": [
        "# 5) LOAD DATASET + TRAIN/VALIDATION SPLIT\n",
        "\n",
        " This block loads the multilabel dataset generated in Notebook 1.\n",
        " It then creates:\n",
        "  - a training subset (80%)\n",
        "  - a validation subset (20%)\n",
        "\n",
        " Finally, it converts both DataFrames into tf.data pipelines using make_ds().\n",
        "\n",
        " Input files expected:\n",
        "   - LABELS_CSV  -> dataset/labels.csv\n",
        "   - IMAGES_DIR  -> dataset/images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "51a19efd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Train samples: 4640\n",
            "✅ Val samples  : 1160\n",
            "✅ Clases: ['lacteos', 'arroz', 'frutas/verduras']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(LABELS_CSV)\n",
        "df[\"path\"] = df[\"filename\"].apply(lambda f: os.path.join(IMAGES_DIR, f))\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=SEED, shuffle=True)\n",
        "\n",
        "train_ds = make_ds(train_df, True)\n",
        "val_ds = make_ds(val_df, False)\n",
        "\n",
        "print(\"✅ Train samples:\", len(train_df))\n",
        "print(\"✅ Val samples  :\", len(val_df))\n",
        "print(\"✅ Clases:\", CLASSES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d1bb77",
      "metadata": {},
      "source": [
        "The dataset was successfully loaded and split into two subsets:\n",
        "\n",
        "Train samples: 4,640 → these images will be used to fit (train) the model, meaning the model updates its weights using this data.\n",
        "\n",
        "Validation samples: 1,160 → these images will be used to evaluate the model during training, helping monitor performance and detect overfitting.\n",
        "\n",
        "The training process is configured for three multilabel classes:\n",
        "\n",
        "['lacteos', 'arroz', 'frutas/verduras']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ee5126",
      "metadata": {},
      "source": [
        "# 6) TRAINING LOOP (Head training + Fine-tuning with MLflow logging)\n",
        "\n",
        " This block runs the actual training process and tracks everything with MLflow.\n",
        "\n",
        " What it does:\n",
        "   1) Creates/sets an MLflow experiment\n",
        "   2) Starts an MLflow run and logs key hyperparameters\n",
        "   3) Builds the model depending on the selected STAGE:\n",
        "        - \"head\": create a new model, freeze backbone, train only the head\n",
        "        - \"finetune\": load saved model, unfreeze last layers, continue training\n",
        "   4) Defines callbacks (early stopping, checkpointing, MLflow metrics)\n",
        "   5) Trains the model (model.fit)\n",
        "   6) Logs the trained model file as an MLflow artifact\n",
        "\n",
        " Output:\n",
        "   - Saved Keras model at outputs/model.keras\n",
        "   - MLflow run with parameters + metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7de568c4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/02/01 20:33:49 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/02/01 20:33:49 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/02/01 20:33:49 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/02/01 20:33:49 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/02/01 20:33:49 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/02/01 20:33:49 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "2026/02/01 20:33:50 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2026/02/01 20:33:50 INFO mlflow.store.db.utils: Updating database tables\n",
            "2026/02/01 20:33:50 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/02/01 20:33:50 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2026/02/01 20:33:50 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/02/01 20:33:50 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m3,843\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,261,827</span> (8.63 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,261,827\u001b[0m (8.63 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> (15.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,843\u001b[0m (15.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 750ms/step - auc: 0.9060 - bin_acc: 0.8150 - loss: 0.4482 - val_auc: 0.9628 - val_bin_acc: 0.8968 - val_loss: 0.2696\n",
            "Epoch 2/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 702ms/step - auc: 0.9734 - bin_acc: 0.9129 - loss: 0.2305 - val_auc: 0.9788 - val_bin_acc: 0.9239 - val_loss: 0.2063\n",
            "Epoch 3/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 701ms/step - auc: 0.9828 - bin_acc: 0.9324 - loss: 0.1849 - val_auc: 0.9836 - val_bin_acc: 0.9319 - val_loss: 0.1800\n",
            "Epoch 4/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 700ms/step - auc: 0.9860 - bin_acc: 0.9398 - loss: 0.1655 - val_auc: 0.9865 - val_bin_acc: 0.9417 - val_loss: 0.1628\n",
            "Epoch 5/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 751ms/step - auc: 0.9891 - bin_acc: 0.9473 - loss: 0.1474 - val_auc: 0.9878 - val_bin_acc: 0.9443 - val_loss: 0.1517\n",
            "Epoch 6/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 709ms/step - auc: 0.9900 - bin_acc: 0.9508 - loss: 0.1392 - val_auc: 0.9889 - val_bin_acc: 0.9509 - val_loss: 0.1447\n",
            "Epoch 7/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 722ms/step - auc: 0.9918 - bin_acc: 0.9541 - loss: 0.1261 - val_auc: 0.9903 - val_bin_acc: 0.9537 - val_loss: 0.1350\n",
            "Epoch 8/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 703ms/step - auc: 0.9926 - bin_acc: 0.9570 - loss: 0.1207 - val_auc: 0.9907 - val_bin_acc: 0.9560 - val_loss: 0.1314\n",
            "Epoch 9/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 708ms/step - auc: 0.9931 - bin_acc: 0.9574 - loss: 0.1160 - val_auc: 0.9911 - val_bin_acc: 0.9549 - val_loss: 0.1284\n",
            "Epoch 10/10\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 734ms/step - auc: 0.9940 - bin_acc: 0.9610 - loss: 0.1081 - val_auc: 0.9918 - val_bin_acc: 0.9557 - val_loss: 0.1227\n",
            "\n",
            "✅ Modelo guardado en: outputs\\model.keras\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
        "\n",
        " #Log training parameters (hyperparameters & metadata)\n",
        "with mlflow.start_run(run_name=RUN_NAME):\n",
        "    mlflow.log_params({\n",
        "        \"stage\": STAGE,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"batch\": BATCH,\n",
        "        \"img_size\": IMG_SIZE[0],\n",
        "        \"classes\": \",\".join(CLASSES),\n",
        "        \"neg_weight\": NEG_WEIGHT,\n",
        "        \"pos_weight\": POS_WEIGHT,\n",
        "    })\n",
        "\n",
        "# Build or load the model depending on the stage\n",
        "    if STAGE == \"head\":\n",
        "        lr = LR if LR is not None else 1e-3\n",
        "        model = build_model()\n",
        "        model = compile_model(model, lr)\n",
        "        mlflow.log_param(\"lr\", lr)\n",
        "\n",
        "    elif STAGE == \"finetune\":\n",
        "        if not os.path.isfile(MODEL_PATH):\n",
        "            raise FileNotFoundError(f\"No existe {MODEL_PATH}. Primero corre STAGE='head'.\")\n",
        "\n",
        "        lr = LR if LR is not None else 1e-4\n",
        "        model = tf.keras.models.load_model(MODEL_PATH)\n",
        "        model = unfreeze_last_layers(model, n_layers=UNFREEZE_LAYERS)\n",
        "        model = compile_model(model, lr)\n",
        "\n",
        "        mlflow.log_param(\"lr\", lr)\n",
        "        mlflow.log_param(\"unfreeze_layers\", UNFREEZE_LAYERS)\n",
        "    else:\n",
        "        raise ValueError(\"STAGE debe ser 'head' o 'finetune'\")\n",
        "\n",
        "    model.summary()\n",
        "    # Training callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ModelCheckpoint(MODEL_PATH, save_best_only=True),\n",
        "        MLflowMetricsCallback(),\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    #Log the saved model as an MLflow artifact\n",
        "    mlflow.log_artifact(MODEL_PATH)\n",
        "\n",
        "print(\"\\n✅ Modelo guardado en:\", MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c8a2013",
      "metadata": {},
      "source": [
        "# Conclusions \n",
        "\n",
        "The multilabel training process using MobileNetV2 pretrained on ImageNet was completed successfully, confirming that the pipeline works correctly from data loading to model saving.\n",
        "\n",
        "The model achieved high performance, reaching approximately 96% binary accuracy and a validation AUC close to 0.99, which indicates strong classification capability for the three target classes.\n",
        "\n",
        "The continuous decrease in loss across epochs shows that the model learned stable and meaningful patterns without major training instability.\n",
        "\n",
        "The final model was saved correctly as outputs/model.keras, making it ready for future testing, inference, and deployment through a web interface such as Flask."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
